<!DOCTYPE HTML>
<html lang="en">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

    <title>Tiansheng Wen(ÊñáÊ∑ªÂú£)</title>

    <meta name="author" content="Tiansheng Wen">
    <meta name="viewport" content="width=device-width, initial-scale=1">

    <link rel="stylesheet" type="text/css" href="stylesheet.css">
    <link rel="icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>üåê</text></svg>">
  </head>

  <body>
    <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
      <tr style="padding:0px">
        <td style="padding:0px">
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr style="padding:0px">
              <td style="padding:2.5%;width:63%;vertical-align:middle">
                <p class="name" style="text-align: center;">
                  Tiansheng Wen(ÊñáÊ∑ªÂú£)
                </p>
                <p>
                  Howdy! Welcome to my home page.
                  I am a second-year M.S. student at Xidian University, advised by Prof. <a href="https://web.xidian.edu.cn/bchen/">Bo Chen</a>. Concurrently, I serve as a Research Intern at Stony Brook University, working with Prof. <a href="https://chenyuyou.me/">Chenyu You</a>. Prior to my graduate studies, I received my B.S. degree from Xidian University in 2023.
                </p>
                 <!-- Previously, I was a research intern in <a href="https://whitneylab.berkeley.edu/">Whitney's Lab</a>
                  , University of California, Berkeley, advised by 
                  <a href="https://vcresearch.berkeley.edu/faculty/david-whitney">David Whitney</a>.  -->
                  <!-- I was also fortunate to be advised by
                  <a href="http://people.csail.mit.edu/ganchuang/">Chuang Gan</a>, working with
                  <a href="https://people.csail.mit.edu/yban/index.html">Yutong Ban</a>.  -->
                  <!-- Currently, I'm advised by
                  <a href="https://www.saying.ren/">Kan Ren</a> -->
                
                <p style="text-align:center">
                  <a href="https://scholar.google.com.hk/citations?hl=zh-CN&user=mrdyOyQAAAAJ">Google Scholar</a> &nbsp;/&nbsp;
                  <a href="mailto:neilwen987@gmail.com">Email</a> &nbsp;/&nbsp;
                  <a href="data/CV_3_9.pdf">CV</a> &nbsp;/&nbsp;
                  <!-- <a href="data/JonBarron-bio.txt">Bio</a> &nbsp;/&nbsp; -->
                  <a href="https://github.com/neilwen987">Github</a> &nbsp;/&nbsp;
                  <!-- <a href="https://www.semanticscholar.org/author/Yifan-Wang/2239578649">Semantic Scholar</a> &nbsp;/&nbsp; -->
                  <a href="https://x.com/tianshengv111?s=21">X</a>/
<!--                  <! &#45;&#45; <a href="https://www.linkedin.com/in/yifan-wang-92a593249/">Linkedin</a>&nbsp;/&nbsp; &ndash;&gt;-->
                </p>
              </td>
              <td style="padding:2.5%;width:40%;max-width:40%">
                <a href="img/profile.png"><img style="width:100%;max-width:100%" alt="profile photo" src="img/profile.png" class="hoverZoomLink"></a>
              </td>
            </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
              <tr>
              <td style="padding:20px;width:100%;vertical-align:middle">
                <h1>üßêüßê Research Interests</h1>
                  <div class="research-content">

                    <p>My primary research goal is to develop scalable, <b>reliable and efficient methods</b> for machine learning and generative AI. Currently, I focus on the following key directions:</p>

                      <ol class="research-directions">
                          <li>Bayesian methods for disentangled representations and uncertainty estimation</li>
                          <li>Alignment and safety of Foundation models, including LLMs, VLMs, and diffusion models</li>
                      </ol>

                      <p>In addition, I am also highly interested in:</p>
                      <ul class="other-interests">
                          <li>üìö Memorization in large models</li>
                          <li>üîÑ Self-consuming/self-improving loops</li>
                          <li>ü§ñ Agent learning with Foundation models</li>
                      </ul>

                      <p>If you share the same research interests, feel free to reach out or add my
                          <a href="./img/wechat_qr.png" class="wechat-link">
                              Wechat
<!--                              <img src="./img/wechat_qr.png" alt="WeChat QR Code">-->
                          </a>
                      </p>
                  </div>
              </td>
            </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <h1>üöÄüöÄ News</h1>
              <p>
                03-2025: Code for our paper <a href="https://arxiv.org/abs/2503.01776">CSR</a> has been released,
                and we were invited to publish the model on HuggingFace. ‚öôÔ∏è‚öôÔ∏è
              </p>
              <p>
                02-2025: One paper was accepted by CVPR 2025! üéâüéâ
              </p>
              <p>
                07-2024: Our paper <a href="https://arxiv.org/abs/2407.18589">HICE-Score</a> was accepted by ACM MM 2024! üéâüéâ
              </p>
            </td>
          </tr>
        </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
          <td style="padding:20px;width:100%;vertical-align:middle">
            <h2>Publications</h2>
          </td>
        </tr>
      </tbody></table>

          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            
            <tr onmouseout="alignerf_stop()" onmouseover="alignerf_start()">
              <td style="padding:20px;width:25%;vertical-align:middle">
                <div class="one">
                  <img src='img/iclr25.png' width="160" height="140">
                </div>
              </td>
              <td style="padding:20px;width:75%;vertical-align:middle">
                <a href="https://yfwang.me/">
                  <span class="papertitle">Discovering Influential Neuron Path in Vision Transformers</span>
                </a>
                <br>
                  <b>Yifan Wang</b>,
                  Yifei Liu,
                  Yingdong Shi,
                  Changming Li,
                  Anqi Pang,
                  Sibei Yang,
                  Jingyi Yu,
                  Kan Ren
                <br>
                <em>ICLR</em>, 2025
                <br>
                /
                <a href="https://yfwang.me/">paper</a>
                /
                <p></p>
                <p>
                  We propose a method to identify and trace neuron path, 
                  the most influential neurons across layers in vision Transformers, 
                  revealing their internal mechanisms and enabling applications like model pruning.
                </p>
              </td>
            </tr>


            <tr onmouseout="alignerf_stop()" onmouseover="alignerf_start()">
              <td style="padding:20px;width:25%;vertical-align:middle">
                <div class="one">
                  <img src='img/vqpatch.png' width="160" height="140">
                </div>
              </td>
              <td style="padding:20px;width:75%;vertical-align:middle">
                <a href="https://arxiv.org/abs/2401.10278">
                  <span class="papertitle">EEGFormer: Towards Transferable and Interpretable Large-Scale EEG Foundation Model</span>
                </a>
                <br>
                  Yuqi Chen,
                  <a href="https://www.saying.ren/">Kan Ren</a>,
                  Kaitao Song,
                  Yansen Wang,
                  <b>Yifan Wang</b>,
                  Dongsheng Li,
                  Lili Qiu
                <br>
                <em>AAAI</em>, 2024 SSS on Clinical FMs
                <!-- <em>Under Review</em> -->
                <br>
                /
                <a href="https://arxiv.org/abs/2401.10278">arXiv</a>
                /
                <p></p>
                <p>
                  A novel pretrained EEG foundation model (EEGFormer)
                  cannot only learn universal representations on EEG signals with adaptable performance on various 
                  downstream tasks but also provide interpretable outcomes of the useful patterns within the data.
                </p>
              </td>
            </tr>

            <tr onmouseout="alignerf_stop()" onmouseover="alignerf_start()">
              <td style="padding:20px;width:25%;vertical-align:middle">
                <div class="one">
                  <img src='img/veatic.png' width="160">
                </div>
              </td>
              <td style="padding:20px;width:75%;vertical-align:middle">
                <a href="https://veatic.github.io/">
                  <span class="papertitle">VEATIC: Video-based Emotion and Affect Tracking in Context Dataset</span>
                </a>
                <br>
                  <a href="https://albuspeter.github.io/">Zhihang Ren</a><sup>*</sup>
                  <a href="https://www.jeffersonortega.me/">Jefferson Ortega</a><sup>*</sup>
                  <b>Yifan Wang</b><sup>*</sup>
                  Zhimin Chen,
                  <a href="https://whitneylab.berkeley.edu/people/dave.html">David Whitney</a>,
                  <a href="https://yunhuiguo.github.io/">Yunhui Guo</a>,
                  <a href="https://web.eecs.umich.edu/~stellayu/">Stella Yu</a>
                  (* Equal contribution)
                <br>
                <em>WACV</em>, 2024
                <!-- <em>Under Review</em> -->
                <br>
                <a href="https://veatic.github.io/">project page</a>
                /
                <a href="https://openaccess.thecvf.com/content/WACV2024/papers/Ren_VEATIC_Video-Based_Emotion_and_Affect_Tracking_in_Context_Dataset_WACV_2024_paper.pdf">paper</a>
                /
                <a href="https://github.com/AlbusPeter/VEATIC">code</a>
                <p></p>
                <p>
                  A brand new large dataset, the Video-based Emotion and Affect Tracking in Context Dataset (VEATIC), 
                  that can conquer the limitations of the previous datasets.
                </p>
              </td>
            </tr>
      

          </tbody></table>

          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <h2>Selected Awards and Honors</h2>
              <p>
                06-2024: I received the honor of being the <b>Outstanding Graduate</b> in ShanghaiTech.
              </p>
              <p>
                12-2023: I received the honor of being 2022-2023 <b>Merit Student</b> in ShanghaiTech.
              </p>
              <p>
                07-2023: I received the <b>Undergraduate International Exchange Special Scholarship</b> in ShanghaiTech.
              </p>
              <p>
                12-2022: I received the honor of being 2021-2022 <b>Merit Student</b> in ShanghaiTech.
              </p>
            </td>
          </tr>
        </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
          <td style="padding:20px;width:100%;vertical-align:middle">
            <h2>Service</h2>
            <p>
              Reviewer: TNNLS, TMI, CVPR25
            </p>
          </td>
        </tr>
      </tbody></table>
            

          <script type="text/javascript" id="clustrmaps" src="//cdn.clustrmaps.com/map_v2.js?cl=ffffff&w=200&t=n&d=5Mbudn0FSMUmDjHq2NxUjvoq_vySIg_giud-A4yWPHk"></script>

          
        </td>
      </tr>
    </table>
  </body>
</html>